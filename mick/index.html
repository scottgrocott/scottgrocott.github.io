<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MIDI Canvas</title>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Space+Mono:wght@400;700&display=swap');
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { width: 100vw; height: 100vh; overflow: hidden; background: #000; font-family: 'Space Mono', monospace; }
    #canvas-container { position: fixed; inset: 0; z-index: 0; }
    #canvas-container canvas { display: block; }

    #ui {
      position: fixed; top: 0; left: 0; right: 0; z-index: 10;
      display: flex; align-items: center; gap: 16px; padding: 16px 24px;
      background: linear-gradient(to bottom, rgba(0,0,0,0.85) 0%, transparent 100%);
      pointer-events: none;
    }
    #ui > * { pointer-events: all; }
    .label { color: #888; font-size: 10px; letter-spacing: 0.15em; text-transform: uppercase; }
    #midi-select {
      background: rgba(255,255,255,0.05); border: 1px solid rgba(255,255,255,0.15);
      color: #fff; font-family: 'Space Mono', monospace; font-size: 12px;
      padding: 8px 14px; border-radius: 4px; outline: none; cursor: pointer; min-width: 220px;
      appearance: none; -webkit-appearance: none;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='12' height='12' fill='%23888' viewBox='0 0 16 16'%3E%3Cpath d='M7.247 11.14L2.451 5.658C1.885 5.013 2.345 4 3.204 4h9.592a1 1 0 0 1 .753 1.659l-4.796 5.48a1 1 0 0 1-1.506 0z'/%3E%3C/svg%3E");
      background-repeat: no-repeat; background-position: right 10px center; padding-right: 30px;
    }
    #midi-select:hover { border-color: rgba(255,255,255,0.35); }
    #status-dot { width: 8px; height: 8px; border-radius: 50%; background: #333; flex-shrink: 0; transition: background 0.3s; }
    #status-dot.connected { background: #00ff88; box-shadow: 0 0 8px #00ff88; }
    #status-dot.playing   { background: #ff6600; box-shadow: 0 0 12px #ff6600; }
    #status-dot.error     { background: #ff4455; }
    #status-text { color: #555; font-size: 10px; letter-spacing: 0.1em; }

    #tone-btn {
      position: fixed; top: 60px; left: 50%; transform: translateX(-50%);
      z-index: 30; background: #ff6600; color: #000; font-family: 'Space Mono', monospace;
      font-size: 13px; font-weight: 700; padding: 12px 28px; border: none;
      border-radius: 4px; cursor: pointer; letter-spacing: 0.1em; transition: opacity 0.3s;
    }
    #tone-btn:hover { background: #ff8833; }
    #tone-btn.hidden { opacity: 0; pointer-events: none; }

    #note-display { position: fixed; inset: 0; z-index: 5; display: flex; align-items: center; justify-content: center; pointer-events: none; }
    #note-text {
      font-family: 'Bebas Neue', sans-serif; font-size: clamp(80px, 20vw, 280px);
      color: #111; letter-spacing: 0.02em; text-align: center; line-height: 1;
      opacity: 0; transform: scale(0.88);
      transition: opacity 0.06s ease-out, transform 0.06s ease-out;
      user-select: none;
    }
    #note-text.visible { opacity: 1; transform: scale(1); }

    #footer {
      position: fixed; bottom: 20px; left: 50%; transform: translateX(-50%);
      z-index: 10; color: #444; font-size: 10px; letter-spacing: 0.12em;
      text-transform: uppercase; pointer-events: none; white-space: nowrap;
    }

    #debug-log {
      position: fixed; bottom: 0; left: 0; right: 0; z-index: 20;
      background: rgba(0,0,0,0.9); padding: 8px 14px; font-size: 11px;
      color: #0f0; letter-spacing: 0.04em; height: 200px; overflow-y: auto;
      pointer-events: none; border-top: 1px solid #222; display: none;
    }
    #debug-log.visible { display: block; }
    #debug-log .row      { margin: 1px 0; white-space: pre; }
    #debug-log .row.warn { color: #ff0; }
    #debug-log .row.err  { color: #f55; }
    #debug-log .row.good { color: #0ff; }
    #debug-log .row.skip { color: #444; }

    #no-midi-warning {
      position: fixed; inset: 0; z-index: 20; flex-direction: column;
      align-items: center; justify-content: center; background: rgba(0,0,0,0.92);
      color: #fff; gap: 16px; display: none;
    }
    #no-midi-warning h2 { font-family: 'Bebas Neue', sans-serif; font-size: 48px; color: #ff4455; }
    #no-midi-warning p  { font-size: 12px; color: #888; max-width: 400px; text-align: center; line-height: 1.8; }
  </style>
</head>
<body>

<div id="canvas-container"></div>
<div id="ui">
  <span class="label">Device</span>
  <select id="midi-select"><option value="">— Select MIDI input —</option></select>
  <div id="status-dot"></div>
  <span id="status-text">No device</span>
</div>
<button id="tone-btn">▶ CLICK TO ENABLE AUDIO</button>
<div id="note-display"><div id="note-text"></div></div>
<div id="footer">Play a note or chord</div>
<div id="no-midi-warning">
  <h2>MIDI Not Supported</h2>
  <p>Your browser doesn't support the Web MIDI API. Please use Chrome or Edge.</p>
</div>
<div id="debug-log"></div>

<script type="importmap">
{ "imports": { "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js" } }
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.49/Tone.js"></script>

<script type="module">
import * as THREE from 'three';

/* ═══════════════════════════════════════════════════════════════
   GR-55 FILTER SETTINGS
   ═══════════════════════════════════════════════════════════════ */
const MIN_VELOCITY  = 25;          // below = ghost tracking note, ignore
const BLOCKED_CH    = new Set([14, 15]); // ch15/16 = GR-55 control data

/* ═══════════════════════════════════════════════════════════════
   ARCHITECTURE NOTE
   ─────────────────────────────────────────────────────────────
   The PolySynth was getting corrupted by repeated triggerRelease()
   calls on voices that were already gone. New approach:

   DISPLAY STATE  — activeNotes Map, driven purely by note-on/off.
                    Has its own 10s timeout so the screen clears.
                    Never touches the synth.

   AUDIO          — Each note-on fires triggerAttackRelease() with
                    a generous fixed duration (4s). The synth handles
                    its own voice lifecycle completely. Note-offs just
                    call triggerRelease() once with no state tracking.
                    If the synth already released that voice, Tone.js
                    silently ignores it — no corruption.

   This decouples the two systems entirely.
   ═══════════════════════════════════════════════════════════════ */

/* ─── DEBUG ── */
const logEl = document.getElementById('debug-log');
let debugOn = false;
document.addEventListener('keydown', e => {
  if (e.key === '`') { debugOn = !debugOn; logEl.classList.toggle('visible', debugOn); }
});
function dbg(msg, type = '') {
  const d  = new Date();
  const ts = `${String(d.getMinutes()).padStart(2,'0')}:${String(d.getSeconds()).padStart(2,'0')}.${String(d.getMilliseconds()).padStart(3,'0')}`;
  const row = document.createElement('div');
  row.className = `row ${type}`;
  row.textContent = `[${ts}] ${msg}`;
  logEl.appendChild(row);
  logEl.scrollTop = logEl.scrollHeight;
  while (logEl.children.length > 80) logEl.removeChild(logEl.firstChild);
  console.log('[DBG]', msg);
}

/* ─── THREE ── */
const container = document.getElementById('canvas-container');
const scene     = new THREE.Scene();
scene.background = new THREE.Color(0x050505);
const camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 100);
camera.position.set(0, 0, 2);
const renderer = new THREE.WebGLRenderer({ antialias: true });
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
container.appendChild(renderer.domElement);

function viewSize() {
  const h = 2 * Math.tan((45 * Math.PI / 180) / 2) * camera.position.z;
  return { w: h * camera.aspect, h };
}
let { w: pW, h: pH } = viewSize();
const planeMat = new THREE.MeshBasicMaterial({ color: 0xffffff });
const plane    = new THREE.Mesh(new THREE.PlaneGeometry(pW, pH), planeMat);
scene.add(plane);
const vignetteMat = new THREE.ShaderMaterial({
  transparent: true, depthWrite: false,
  uniforms: { uOpacity: { value: 0.0 } },
  vertexShader:   `varying vec2 vUv; void main(){ vUv=uv; gl_Position=projectionMatrix*modelViewMatrix*vec4(position,1.); }`,
  fragmentShader: `uniform float uOpacity; varying vec2 vUv;
    void main(){ vec2 d=vUv-0.5; float v=smoothstep(0.25,0.85,length(d)*1.6); gl_FragColor=vec4(0.,0.,0.,v*uOpacity); }`
});
const vignette = new THREE.Mesh(new THREE.PlaneGeometry(pW*1.2, pH*1.2), vignetteMat);
vignette.position.z = 0.01;
scene.add(vignette);
let vigTarget = 0;
window.addEventListener('resize', () => {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
  const { w, h } = viewSize();
  plane.geometry.dispose();    plane.geometry    = new THREE.PlaneGeometry(w, h);
  vignette.geometry.dispose(); vignette.geometry = new THREE.PlaneGeometry(w*1.2, h*1.2);
});
renderer.setAnimationLoop(() => {
  vignetteMat.uniforms.uOpacity.value += (vigTarget - vignetteMat.uniforms.uOpacity.value) * 0.1;
  renderer.render(scene, camera);
});

/* ─── TONE — fire-and-forget model ── */
let toneReady   = false;
let tonePromise = null;
let polySynth   = null;
const toneBtn   = document.getElementById('tone-btn');

async function initTone() {
  if (tonePromise) return tonePromise;
  tonePromise = (async () => {
    try {
      await Tone.start();
      dbg('AudioContext: ' + Tone.context.state, 'good');
      const reverb = new Tone.Reverb({ decay: 2.0, wet: 0.3 });
      await reverb.ready;
      const chorus = new Tone.Chorus(3, 2, 0.4).start();
      polySynth = new Tone.PolySynth(Tone.Synth, {
        oscillator: { type: 'triangle' },
        envelope:   { attack: 0.02, decay: 0.1, sustain: 0.85, release: 0.8 },
        volume: -8
      });
      polySynth.maxPolyphony = 32;
      polySynth.chain(chorus, reverb, Tone.Destination);
      toneReady = true;
      dbg('PolySynth ready', 'good');
      toneBtn.classList.add('hidden');
    } catch(e) {
      dbg('Tone ERROR: ' + e.message, 'err');
      tonePromise = null;
    }
  })();
  return tonePromise;
}
toneBtn.addEventListener('click', () => initTone());

/* Safely trigger attack. Uses triggerAttack only — release happens either
   on note-off or naturally when the voice is stolen. */
function synthAttack(noteName, velocity) {
  if (!polySynth) return;
  try {
    polySynth.triggerAttack(noteName, Tone.now(), velocity);
  } catch(e) {
    dbg('Attack err: ' + e.message, 'err');
  }
}

/* Safely trigger release. Tone.js silently ignores release of a voice
   that isn't playing — this is safe to call speculatively. */
function synthRelease(noteName) {
  if (!polySynth) return;
  try {
    polySynth.triggerRelease(noteName, Tone.now());
  } catch(e) {
    // ignore — voice was already gone
  }
}

/* ─── NOTE NAMES ── */
const NOTE_NAMES = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B'];
function midiNoteToName(midi) { return NOTE_NAMES[midi % 12] + (Math.floor(midi / 12) - 1); }

const CHORD_PATTERNS = [
  { intervals:[0,4,7],    suffix:'maj'  }, { intervals:[0,3,7],    suffix:'min'  },
  { intervals:[0,3,6],    suffix:'dim'  }, { intervals:[0,4,8],    suffix:'aug'  },
  { intervals:[0,4,7,11], suffix:'maj7' }, { intervals:[0,4,7,10], suffix:'7'    },
  { intervals:[0,3,7,10], suffix:'min7' }, { intervals:[0,3,6,10], suffix:'m7b5' },
  { intervals:[0,3,6,9],  suffix:'dim7' }, { intervals:[0,5,7],    suffix:'sus4' },
  { intervals:[0,2,7],    suffix:'sus2' },
];
function detectChord(nums) {
  if (!nums.length) return '';
  if (nums.length === 1) return NOTE_NAMES[nums[0] % 12];
  const pcs = [...new Set(nums.map(n => n % 12))].sort((a,b) => a-b);
  for (const root of pcs) {
    const ivs = pcs.map(pc => ((pc - root) + 12) % 12).sort((a,b) => a-b);
    for (const p of CHORD_PATTERNS) {
      if (JSON.stringify(ivs) === JSON.stringify(p.intervals)) return NOTE_NAMES[root] + ' ' + p.suffix;
    }
  }
  return pcs.map(pc => NOTE_NAMES[pc]).join(' · ');
}

/* ─── DISPLAY STATE (decoupled from audio) ──────────────────────────────────
   Tracks which notes are "visually active" for chord detection and display.
   Has its own generous timeout (10s) so held notes don't vanish from screen.
   Does NOT drive the synth — that's handled separately above.           */
const activeNotes   = new Map();  // "ch:noteNum" → { noteName, timer }
const DISPLAY_TIMEOUT_MS = 10000; // 10s — generous for long held notes

function displayNoteOn(key, noteName) {
  // Cancel any existing display timer for this key
  if (activeNotes.has(key)) {
    clearTimeout(activeNotes.get(key).timer);
  }
  const timer = setTimeout(() => {
    activeNotes.delete(key);
    updateDisplay();
    if (!activeNotes.size) setStatus('connected', 'Connected');
  }, DISPLAY_TIMEOUT_MS);
  activeNotes.set(key, { noteName, timer });
}

function displayNoteOff(key) {
  if (!activeNotes.has(key)) return;
  clearTimeout(activeNotes.get(key).timer);
  activeNotes.delete(key);
}

function clearAllDisplay() {
  for (const { timer } of activeNotes.values()) clearTimeout(timer);
  activeNotes.clear();
}

/* ─── DISPLAY ── */
const noteTextEl = document.getElementById('note-text');
const footerEl   = document.getElementById('footer');
function updateDisplay() {
  const entries = [...activeNotes.values()];
  const nums    = [...activeNotes.keys()].map(k => parseInt(k.split(':')[1], 10));
  if (!entries.length) {
    noteTextEl.classList.remove('visible');
    vigTarget = 0;
    footerEl.textContent = 'Play a note or chord';
    return;
  }
  const label = detectChord(nums);
  noteTextEl.textContent = label;
  noteTextEl.classList.add('visible');
  vigTarget = 0.6;
  footerEl.textContent = nums.length === 1
    ? `${entries[0].noteName}  ·  MIDI ${nums[0]}`
    : `${nums.length} notes  ·  ${label}`;
}

/* ─── MIDI ── */
const midiSelectEl = document.getElementById('midi-select');
const statusDotEl  = document.getElementById('status-dot');
const statusTextEl = document.getElementById('status-text');
let midiAccess  = null;
let activeInput = null;
function setStatus(cls, msg) { statusDotEl.className = cls; statusTextEl.textContent = msg; }

async function onMidiMessage(event) {
  const raw    = event.data;
  const status = raw[0];

  // Drop all system realtime messages (clock, active sense, etc.)
  if (status >= 0xF0) return;

  const data1 = raw[1] ?? 0;
  const data2 = raw[2] ?? 0;
  const type  = status & 0xF0;
  const ch    = status & 0x0F;

  // Drop GR-55 control channels
  if (BLOCKED_CH.has(ch)) return;

  // Only care about note messages — silently drop CC, pitch bend, aftertouch
  if (type !== 0x90 && type !== 0x80) return;

  const noteName = midiNoteToName(data1);
  const key      = `${ch}:${data1}`;
  const isOn     = type === 0x90 && data2 > 0;

  if (isOn) {
    // Drop GR-55 ghost tracking notes
    if (data2 < MIN_VELOCITY) {
      dbg(`ghost ${data1}(${noteName}) vel=${data2}`, 'skip');
      return;
    }

    dbg(`ON  ch=${ch} ${data1}(${noteName}) vel=${data2}`, 'good');

    if (!toneReady) { await initTone(); }

    // Audio: if already playing this pitch, release it cleanly first
    if (activeNotes.has(key)) {
      synthRelease(noteName);
    }

    // Audio: attack
    synthAttack(noteName, data2 / 127);

    // Display: register
    displayNoteOn(key, noteName);

    setStatus('playing', 'Playing');
    updateDisplay();

  } else {
    // Note OFF
    if (!activeNotes.has(key)) return; // was a ghost we never registered

    dbg(`OFF ch=${ch} ${data1}(${noteName})`);

    // Audio: release
    synthRelease(noteName);

    // Display: remove
    displayNoteOff(key);

    if (!activeNotes.size) setStatus('connected', 'Connected');
    updateDisplay();
  }
}

function connectInput(inputId) {
  if (activeInput) { activeInput.onmidimessage = null; activeInput = null; }
  clearAllDisplay();
  if (polySynth) { try { polySynth.releaseAll(); } catch(e) {} }
  updateDisplay();
  if (!inputId || !midiAccess) { setStatus('', 'No device'); return; }
  activeInput = midiAccess.inputs.get(inputId);
  if (activeInput) {
    activeInput.onmidimessage = onMidiMessage;
    setStatus('connected', activeInput.name);
    dbg(`Listening: "${activeInput.name}"`, 'good');
  }
}

function populateInputs() {
  const prev = midiSelectEl.value;
  while (midiSelectEl.options.length > 1) midiSelectEl.remove(1);
  midiAccess.inputs.forEach(inp => {
    const opt = document.createElement('option');
    opt.value = inp.id; opt.textContent = inp.name;
    midiSelectEl.appendChild(opt);
  });
  if (prev && midiAccess.inputs.has(prev)) midiSelectEl.value = prev;
}

midiSelectEl.addEventListener('change', () => connectInput(midiSelectEl.value));

async function initMIDI() {
  if (!('requestMIDIAccess' in navigator)) {
    document.getElementById('no-midi-warning').style.display = 'flex'; return;
  }
  try {
    midiAccess = await navigator.requestMIDIAccess({ sysex: false });
    dbg(`MIDI ready. Inputs: ${midiAccess.inputs.size}`, 'good');
    populateInputs();
    const firstId = midiAccess.inputs.keys().next().value;
    if (firstId) { midiSelectEl.value = firstId; connectInput(firstId); }
    midiAccess.onstatechange = e => {
      populateInputs();
      if (e.port.type === 'input' && e.port.state === 'disconnected'
          && activeInput && activeInput.id === e.port.id) {
        connectInput(''); midiSelectEl.value = ''; setStatus('', 'Disconnected');
      }
    };
  } catch(err) {
    dbg('MIDI denied: ' + err.message, 'err');
    setStatus('error', 'Access denied');
  }
}

initMIDI();
</script>
</body>
</html>